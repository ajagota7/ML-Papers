# ML-Papers
Library of useful machine learning papers

# Inverse Reinforcement Learning

# Alignment
- [Offline Regularised Reinforcement Learning for Large Language Models Alignment](https://arxiv.org/pdf/2405.19107)
- [Show, Donâ€™t Tell: Aligning Language Models with Demonstrated Feedback](https://arxiv.org/pdf/2406.00888)
- [Towards Scalable Automated Alignment of LLMs: A Survey](https://arxiv.org/pdf/2406.01252)
- [Behaviour Alignment via Reward Function Optimization](https://arxiv.org/pdf/2310.19007)



# Off Policy Evaluation 

# Rewards 
- [What Can Learned Intrinsic Rewards Capture?](https://arxiv.org/pdf/1912.05500)
- [Plan-based Reward Shaping for Reinforcement Learning](https://www.cs.kent.ac.uk/people/staff/mg483/documents/grzes08IS.pdf)
- [Reward Design via Online Gradient Ascent](https://web.eecs.umich.edu/~baveja/Papers/SorgSinghLewisNIPS2010.pdf)
# Options



# Concepts 
- [The Geometry of Categorical and Hierarchical Concepts in Large Language Models](https://arxiv.org/pdf/2406.01506)

# Eligibility Traces
- [From Past to Future: Rethinking Eligibility Traces](https://arxiv.org/pdf/2312.12972v1)

