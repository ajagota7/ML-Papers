# ML-Papers
Library of useful machine learning papers

# Inverse Reinforcement Learning

# Alignment
- [Offline Regularised Reinforcement Learning for Large Language Models Alignment](https://arxiv.org/pdf/2405.19107)
- [Show, Donâ€™t Tell: Aligning Language Models with Demonstrated Feedback](https://arxiv.org/pdf/2406.00888)
- [Towards Scalable Automated Alignment of LLMs: A Survey](https://arxiv.org/pdf/2406.01252)
- [Behaviour Alignment via Reward Function Optimization](https://arxiv.org/pdf/2310.19007)



# Off Policy Evaluation 
- [Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning](https://arxiv.org/pdf/1911.06854)


# Rewards 
- [What Can Learned Intrinsic Rewards Capture?](https://arxiv.org/pdf/1912.05500)
- [Plan-based Reward Shaping for Reinforcement Learning](https://www.cs.kent.ac.uk/people/staff/mg483/documents/grzes08IS.pdf)
- [Reward Design via Online Gradient Ascent](https://web.eecs.umich.edu/~baveja/Papers/SorgSinghLewisNIPS2010.pdf)
- [Intrinsically Motivated Reinforcement Learning: An Evolutionary Perspective](https://web.eecs.umich.edu/~baveja/Papers/IMRLIEEETAMDFinal.pdf)
- [Where Do Rewards Come From?](https://web.eecs.umich.edu/~baveja/Papers/singh-lewis-barto-2009-cogsci.pdf)
- [Intrinsically Motivated Reinforcement Learning](https://web.eecs.umich.edu/~baveja/Papers/FinalNIPSIMRL.pdf)
- 

# Options
- [Reward-Respecting Subtasks for Model-Based Reinforcement Learning](https://arxiv.org/pdf/2202.03466)


# Concepts 
- [The Geometry of Categorical and Hierarchical Concepts in Large Language Models](https://arxiv.org/pdf/2406.01506)

# Eligibility Traces
- [From Past to Future: Rethinking Eligibility Traces](https://arxiv.org/pdf/2312.12972v1)

